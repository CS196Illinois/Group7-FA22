{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "1a015e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the resources doc if you haven't already!\n",
    "# Also please add whatever interesting/useful sources you find on there for everyone else!\n",
    "# Also, PLEASE check the documentation file in the Project folder if you are confused about any of the NLTK functions\n",
    "\n",
    "# Text summarization tends to have two approaches: extraction and abstraction\n",
    "# Because abstraction is more complex, we can try to build an extraction algorithm first\n",
    "# Although I would definitely recommend checking it out to get an idea of how we can go forward from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "6c4c7441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For collaborators, right now I'm using the algorithm here:\n",
    "# https://blog.floydhub.com/gentle-introduction-to-text-summarization-in-machine-learning/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "c48df224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TLDR; Our extraction algorithm will go like this:\n",
    "# -obtain data\n",
    "# -process text\n",
    "# -tokenization\n",
    "# -find weighted frequency of words (weigh by sentence length, paragraph length, etc)\n",
    "# -substitute words with their weighted frequencies (exactly what it sounds like)\n",
    "# -sum up the weighted frequencies in each sentence, and the sentences with highest sums make up our summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "b967d231",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/karengao/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/karengao/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Starting off with imports\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "a2410f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should try to make this less memory intensive\n",
    "# paragraphContent should be fetched from database file\n",
    "paragraphContent = \"\"\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "3e131349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create word frequency table for the entire text of the paragraph\n",
    "def create_frequency_table(content):\n",
    "    frequency_table = {}\n",
    "    word_list = word_tokenize(content)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stem = PorterStemmer()\n",
    "    for word in word_list:\n",
    "        word = stem.stem(word)\n",
    "        if word in stop_words:\n",
    "            continue\n",
    "        if word in frequency_table: \n",
    "            frequency_table[word] += 1\n",
    "        else: \n",
    "            frequency_table[word] = 1\n",
    "# making punctuation have 0 frequency to prevent them from skewing our weighted frequency\n",
    "    punctuation = {\";\", \":\", \"'\", \".\", \",\", \"!\", \"?\", \"(\", \")\"}\n",
    "    for word in frequency_table:\n",
    "        if word in punctuation:\n",
    "            frequency_table[word] = 0\n",
    "    return frequency_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "83feb869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes in the word frequency dictionary from create_dictionary_table\n",
    "def create_weighted_table(frequency_table):\n",
    "    weighted_frequency_table = {}\n",
    "    highestfreq = max(frequency_table.values())\n",
    "    for word in frequency_table:\n",
    "        weighted_frequency_table[word] = frequency_table[word] / highestfreq\n",
    "    return weighted_frequency_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "7bee0cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutParagraph(content):\n",
    "    allSentences = sent_tokenize(content)\n",
    "    return allSentences;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "0e69fd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# substitute words in each sentence with weighted frequencies, \n",
    "# sum up the weighted word frequencies in each sentence, these sums will be the sentence's \"score\"\n",
    "# compare the sentence scores, and grab the ones with the highest scores for our summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "924e2ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean sentences using PorterStemmer() and getting rid of stop words, similar to tokenization\n",
    "# we can then calculate the scores in each sentence based on the \"weighted frequencies\" that we\n",
    "# assigned to each of these words in our previously made dictionary\n",
    "def clean_sentences(content):\n",
    "    allSentences = sent_tokenize(content)\n",
    "    stem = PorterStemmer()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    all_clean_sentences = []\n",
    "    for sentence in allSentences:\n",
    "        cleaned_sentence = []\n",
    "        word_list = word_tokenize(sentence)\n",
    "        for word in word_list:\n",
    "            word = stem.stem(word)\n",
    "            if (word not in stop_words):\n",
    "                cleaned_sentence.append(word)\n",
    "        all_clean_sentences.append(cleaned_sentence)\n",
    "    return all_clean_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "7e2e83ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates the frequencies of each sentence as a sentence score, and returns the sentence with the greatest frequency \n",
    "\n",
    "def one_sentence_summary(content):\n",
    "    freq_dict = create_frequency_table(content)\n",
    "    weighted_dict = create_weighted_table(freq_dict)\n",
    "    cleanedSentences = clean_sentences(content)\n",
    "    addedNum = []\n",
    "    \n",
    "    for clean_sentence in cleanedSentences:\n",
    "        num = 0\n",
    "        for token in clean_sentence:\n",
    "            if token in weighted_dict.keys():\n",
    "                num = num + weighted_dict[token]\n",
    "        addedNum.append(num)\n",
    "        \n",
    "    largest = addedNum[0]\n",
    "    numTracker = 0\n",
    "    finalNum = 0\n",
    "    for i in addedNum:\n",
    "        numTracker = numTracker + 1\n",
    "        if i > largest:\n",
    "            largest = i\n",
    "            finalNum = numTracker\n",
    "    # finalNum is the index of the sentence that has the highest score\n",
    "    allSentences = cutParagraph(content)\n",
    "    return allSentences[finalNum - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "d9935c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "content1 = \"\"\"Sally sells seashells by the seashore. She worries that she doesn't have enough seashells to sell on the seashore. She won't give up. Sally wants to sell seashells on the seashore, because she likes to sell seashells on the seashore. She is selling seashells on the seashell shore. How much wood could the woodchuck chuck if the woodchuck could chuck wood? She sells seashells by the seashore.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "3880c04a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sally wants to sell seashells on the seashore, because she likes to sell seashells on the seashore.'"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_sentence_summary(content1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "aa3bd95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(content, degree_of_summarization):\n",
    "    # this time, we are able to summarize larger bodies of text\n",
    "    # we also give the user control over how general the degree of summarization is with another parameter\n",
    "    # degree_of_summarization should be an integer between 0 and 10, with 10 being the highest degree of summarization\n",
    "    # 10 would output a one sentence summary\n",
    "    freq_dict = create_frequency_table(content)\n",
    "    weighted_dict = create_weighted_table(freq_dict)\n",
    "    cleanedSentences = clean_sentences(content)\n",
    "    addedNum = []\n",
    "    \n",
    "    for clean_sentence in cleanedSentences:\n",
    "        num = 0\n",
    "        for token in clean_sentence:\n",
    "            if token in weighted_dict.keys():\n",
    "                num = num + weighted_dict[token]\n",
    "        addedNum.append(num)\n",
    "\n",
    "    # find largest sentence score to compare others against\n",
    "    largest_score = addedNum[0]\n",
    "    for num in addedNum:\n",
    "        if num > largest_score:\n",
    "            largest_score = num\n",
    "\n",
    "    # start collecting sentences\n",
    "    index_list = []\n",
    "    deg = degree_of_summarization\n",
    "    for i in range(len(addedNum)):\n",
    "        if addedNum[i] >= (largest_score * (deg / 10)):\n",
    "            index_list.append(i)\n",
    "    allSentences = cutParagraph(content)\n",
    "    \n",
    "    summary = \"\"\"\"\"\"\n",
    "    for i in index_list:\n",
    "        summary = summary + \" \" + allSentences[i]\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "a93830f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyWords(content):\n",
    "    freq_dict = create_frequency_table(content)\n",
    "    weighted_dict = create_weighted_table(freq_dict)\n",
    "    Sentences = cutParagraph(content)\n",
    "    words = word_tokenize(content)\n",
    "    ps = PorterStemmer()\n",
    "    \n",
    "    finalThree = []\n",
    "    finalThreeSt = []\n",
    "    mass = 0\n",
    "    value = \"\"\n",
    "    value2 = \"\"\n",
    "    for j in words:\n",
    "        for i in weighted_dict.keys():\n",
    "            if ps.stem(j) == i:\n",
    "                if weighted_dict[i] > mass:\n",
    "                    mass = weighted_dict[i]\n",
    "                    value = j\n",
    "                    value2 = i\n",
    "    finalThree.append(value)\n",
    "    finalThreeSt.append(value2)\n",
    "    \n",
    "    mass = 0\n",
    "    for j in words:\n",
    "        for i in weighted_dict.keys():\n",
    "            if ps.stem(j) == i:\n",
    "                if weighted_dict[i] > mass and i != finalThreeSt[0]:\n",
    "                    mass = weighted_dict[i]\n",
    "                    value = j\n",
    "                    value2 = i\n",
    "    finalThree.append(value)\n",
    "    finalThreeSt.append(value2)\n",
    "    \n",
    "    mass = 0\n",
    "    \n",
    "    for i in weighted_dict.keys():\n",
    "        if weighted_dict[i] > mass and i != finalThree[0] and i != finalThree[1]:\n",
    "            mass = weighted_dict[i]\n",
    "            value = i\n",
    "    finalThree.append(value)\n",
    "    \n",
    "    return finalThree\n",
    " \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "e3fa92b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['seashells', 'sells', 'seashel']"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyWords(content1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "03a06539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This a five paragraph text\n",
    "content2 = \"\"\"Twenty seconds were all that was left and Richard could hear each one tick by. Fifteen seconds now remained and the panic began to fully set in. Ten seconds and he wasn't sure he had enough time. Five seconds, four, three, two, one... Don't forget that gifts often come with costs that go beyond their purchase price. When you purchase a child the latest smartphone, you're also committing to a monthly phone bill. When you purchase the latest gaming system, you're likely not going to be satisfied with the games that come with it for long and want to purchase new titles to play. When you buy gifts it's important to remember that some come with additional costs down the road that can be much more expensive than the initial gift itself. He took a sip of the drink. He wasn't sure whether he liked it or not, but at this moment it didn't matter. She had made it especially for him so he would have forced it down even if he had absolutely hated it. That's simply the way things worked. She made him a new-fangled drink each day and he took a sip of it and smiled, saying it was excellent.The bush began to shake. Brad couldn't see what was causing it to shake, but he didn't care. He had a pretty good idea about what was going on and what was happening. He was so confident that he approached the bush carefree and with a smile on his face. That all changed the instant he realized what was actually behind the bush. She looked at her student wondering if she could ever get through. \"You need to learn to think for yourself,\" she wanted to tell him. \"Your friends are holding you back and bringing you down.\" But she didn't because she knew his friends were all that he had and even if that meant a life of misery, he would never give them up.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "eeac02d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Five seconds, four, three, two, one... Don't forget that gifts often come with costs that go beyond their purchase price.\""
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(content2, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "3ec95d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Five seconds, four, three, two, one... Don't forget that gifts often come with costs that go beyond their purchase price. When you purchase the latest gaming system, you're likely not going to be satisfied with the games that come with it for long and want to purchase new titles to play. He wasn't sure whether he liked it or not, but at this moment it didn't matter. She made him a new-fangled drink each day and he took a sip of it and smiled, saying it was excellent.The bush began to shake. Brad couldn't see what was causing it to shake, but he didn't care.\""
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(content2, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "32bd9529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Twenty seconds were all that was left and Richard could hear each one tick by. Ten seconds and he wasn't sure he had enough time. Five seconds, four, three, two, one... Don't forget that gifts often come with costs that go beyond their purchase price. When you purchase the latest gaming system, you're likely not going to be satisfied with the games that come with it for long and want to purchase new titles to play. When you buy gifts it's important to remember that some come with additional costs down the road that can be much more expensive than the initial gift itself. He wasn't sure whether he liked it or not, but at this moment it didn't matter. She made him a new-fangled drink each day and he took a sip of it and smiled, saying it was excellent.The bush began to shake. Brad couldn't see what was causing it to shake, but he didn't care. He had a pretty good idea about what was going on and what was happening. He was so confident that he approached the bush carefree and with a smile on his face. But she didn't because she knew his friends were all that he had and even if that meant a life of misery, he would never give them up.\""
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(content2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "c0fa444f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Twenty seconds were all that was left and Richard could hear each one tick by. Fifteen seconds now remained and the panic began to fully set in. Ten seconds and he wasn\\'t sure he had enough time. Five seconds, four, three, two, one... Don\\'t forget that gifts often come with costs that go beyond their purchase price. When you purchase a child the latest smartphone, you\\'re also committing to a monthly phone bill. When you purchase the latest gaming system, you\\'re likely not going to be satisfied with the games that come with it for long and want to purchase new titles to play. When you buy gifts it\\'s important to remember that some come with additional costs down the road that can be much more expensive than the initial gift itself. He wasn\\'t sure whether he liked it or not, but at this moment it didn\\'t matter. She had made it especially for him so he would have forced it down even if he had absolutely hated it. She made him a new-fangled drink each day and he took a sip of it and smiled, saying it was excellent.The bush began to shake. Brad couldn\\'t see what was causing it to shake, but he didn\\'t care. He had a pretty good idea about what was going on and what was happening. He was so confident that he approached the bush carefree and with a smile on his face. That all changed the instant he realized what was actually behind the bush. She looked at her student wondering if she could ever get through. \"You need to learn to think for yourself,\" she wanted to tell him. \"Your friends are holding you back and bringing you down.\" But she didn\\'t because she knew his friends were all that he had and even if that meant a life of misery, he would never give them up.'"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For some reason, any degree of summarization that's less than 3 returns a summary where every contraction has a backslash in them\n",
    "# I still haven't found the reason for that\n",
    "# For demo purposes, let's just keep the degree of summarization above 4 or so.\n",
    "\n",
    "summarize(content2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7538b1da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
